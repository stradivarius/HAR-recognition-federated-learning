{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "prefix_train = pathlib.Path(\"UCI HAR Dataset split/train\")\n",
    "prefix_test = pathlib.Path(\"UCI HAR Dataset split/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(glob : str, path : pathlib.Path, subject = -1, avoid = -1) -> pd.DataFrame: # idx must be a int TODO\n",
    "    _df = pd.DataFrame()\n",
    "    for idx, fn in enumerate(path.glob(f'**/{glob}.csv')):\n",
    "            if subject in (-1, idx) and idx != avoid: \n",
    "                _df = pd.concat([_df, pd.read_csv(fn, sep=' ',header = None)], ignore_index = True)\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_df = load_df('Xtrain', prefix_train, subject = -1, avoid = 23).to_numpy()\n",
    "train_y_df = load_df('ytrain', prefix_train, subject = -1, avoid = 23).to_numpy()\n",
    "\n",
    "test_x_df = load_df('Xtest', prefix_test, subject = 23).to_numpy()\n",
    "test_y_df = load_df('ytest', prefix_test, subject = 23).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SOM\n",
    "from minisom import MiniSom\n",
    "\n",
    "SOM_DIM = 20\n",
    "SOM_NUM_ITER = 100\n",
    "\n",
    "som = MiniSom(\n",
    "        SOM_DIM,\n",
    "        SOM_DIM,\n",
    "        train_x_df.shape[1], #Number of Features\n",
    "        sigma = 5,\n",
    "        learning_rate = 0.1,\n",
    "        neighborhood_function = \"gaussian\",\n",
    "        activation_distance = \"manhattan\",\n",
    "    )\n",
    "\n",
    "som.random_weights_init(train_x_df)\n",
    "som.train_random(train_x_df, SOM_NUM_ITER, verbose=False)  # random training\n",
    "\n",
    "# weights = som.get_weights()\n",
    "# weights = weights.reshape((-1, weights.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'f1-score': 0.9142857142857143,\n",
      "       'precision': 0.9411764705882353,\n",
      "       'recall': 0.8888888888888888,\n",
      "       'support': 18},\n",
      " '2': {'f1-score': 0.8749999999999999,\n",
      "       'precision': 0.9333333333333333,\n",
      "       'recall': 0.8235294117647058,\n",
      "       'support': 17},\n",
      " '3': {'f1-score': 0.8484848484848485,\n",
      "       'precision': 0.7777777777777778,\n",
      "       'recall': 0.9333333333333333,\n",
      "       'support': 15},\n",
      " '4': {'f1-score': 0.6666666666666666,\n",
      "       'precision': 0.7368421052631579,\n",
      "       'recall': 0.6086956521739131,\n",
      "       'support': 23},\n",
      " '5': {'f1-score': 0.8085106382978724,\n",
      "       'precision': 0.76,\n",
      "       'recall': 0.8636363636363636,\n",
      "       'support': 22},\n",
      " '6': {'f1-score': 0.8936170212765957,\n",
      "       'precision': 0.875,\n",
      "       'recall': 0.9130434782608695,\n",
      "       'support': 23},\n",
      " 'accuracy': 0.8305084745762712,\n",
      " 'macro avg': {'f1-score': 0.8344274815019496,\n",
      "               'precision': 0.837354947827084,\n",
      "               'recall': 0.838521188009679,\n",
      "               'support': 118},\n",
      " 'weighted avg': {'f1-score': 0.8282472410988458,\n",
      "                  'precision': 0.8327701544489339,\n",
      "                  'recall': 0.8305084745762712,\n",
      "                  'support': 118}}\n"
     ]
    }
   ],
   "source": [
    "# Test the SOM\n",
    "from sklearn.metrics import classification_report\n",
    "from pprint import pprint\n",
    "\n",
    "# Find the association between neurons and class\n",
    "winmap = som.labels_map(train_x_df , train_y_df.flatten()) \n",
    "default_class = np.sum( list (winmap.values())).most_common()[0][0] # The most common class in the dataset (when we are undecided)\n",
    "\n",
    "# Test\n",
    "prediction = []\n",
    "for test_sample in test_x_df:\n",
    "    win_position = som.winner(test_sample)\n",
    "    if win_position in winmap:\n",
    "        prediction.append( winmap [ win_position ].most_common()[0][0])\n",
    "    else:\n",
    "        prediction.append(default_class) #FIXME take the neighboring\n",
    "\n",
    "# Eval Accuracy\n",
    "pprint ( classification_report(\n",
    "        test_y_df.flatten(),\n",
    "        prediction,\n",
    "        zero_division=0.0,\n",
    "        output_dict=True,\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
